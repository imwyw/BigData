# 概念

1. 数据同步和传输：Sqoop、OGG
2. 分布式计算框架：MapReduce、Spark、Spark Streamning、Flink
3. 数据媒介：Hive、HBase、Kafka
4. 核心：Hadoop（HDFS+MapReduce+YARN）

## Sqoop

Hadoop和RDB传送数据的工具，其实是一个命令行工具（命令->MR程序），完成MySQL、Oracle和HDFS、Hive、HBase之间的导入和导出。

## OGG

Oracle GoldenGate（OGG）是一种基于日志的结构化数据复制软件，利用抽取进程 (Extract Process)在源端数据库中读取Online Redo Log或者Archive Log，然后进行解析，只提取其中数据的变化信息，比如DML操作——增、删、改操作，将抽取的信息转换为GoldenGate自定义的中间格式存放在队列文件(trail file)中。再利用传输进程将队列文件 (trail file) 通过 TCP/IP传送到目标系统。

## Hadoop
Hadoop是一个分布式系统基础架构，充分利用集群的威力进行高速运算和存储，它解決了两大问题：大数据存储、大数据分析。也就是 Hadoop 的两大核心：HDFS 和 MapReduce。

* HDFS(Hadoop Distributed File System)是可扩展、容错、高性能的分布式文件系统，异步复制，一次写入多次读取，主要负责存储。
* MapReduce 为分布式计算框架，包含map(映射)和 reduce(归约)过程，负责在 HDFS 上进行计算。
* YARN 资源管理架构（Yet Another Resource Manager）包括 ResourceManager（资源管理器）、Applica-tionMaster、NodeManager（节点管理器）。

## Hive
Hive是一个构建在Hadoop之上的数据仓库软件,它可以使已经存储的数据结构化，它提供类似sql的查询语句HiveQL对数据进行分析处理。 Hive将HiveQL语句转换成一系列成MapReduce作业并执行。

## Spark
Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架，比MR更快。Spark 本身使用 Scala 语言编写，提供了 Java、Scala、Python、R 四种语言的 API。

基于Spark，可以用java等做算子开发，包含transformation（中间过程处理）和action（触发SparkContext提交Job作业，并输出）。

也可以使用Spark SQL，其也是一种SQL-on-Hadoop工具，Spark SQL 就是这样一个基于 SQL 的声明式编程接口。你可以将它看作在 Spark 之上的一层封装，在 RDD 计算模型的基础上，提供了 DataFrame API 以及一个内置的 SQL 执行计划优化器 Catalyst。

## Spark Streaming
Spark Streaming 是个批处理的流式（实时）计算框架。其基本原理是把输入数据以某一时间间隔批量的处理，当批处理间隔缩短到秒级时，便可以用于处理实时数据流。

支持从多种数据源获取数据，包括Kafk、Flume、Twitter、ZeroMQ、Kinesis以及TCP sockets，从数据源获取数据之后，可以使用诸如map、reduce、join等高级函数进行复杂算法的处理。最后还可以将处理结果存储到文件系统，数据库（HDFS、HBase）等。

## Flink
分布式流处理计算框架，其核心是用Java和Scala编写的分布式流数据流引擎。Flink以数据并行和流水线方式执行任意流数据程序，Flink的流水线运行时系统可以执行批处理和流处理程序。

## HBase
HBase是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。HBase利用Hadoop HDFS作为其文件存储系统。


















